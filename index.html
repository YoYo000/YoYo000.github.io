<!DOCTYPE HTML>
<!--
	Iridium by TEMPLATED
    templated.co @templatedco
    Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>
		<title>Yao Yao</title>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="description" content="" />
		<meta name="keywords" content="" />
		<!-- <link href='http://fonts.googleapis.com/css?family=Arimo:400,700' rel='stylesheet' type='text/css'> -->
		<!--[if lte IE 8]><script src="js/html5shiv.js"></script><![endif]-->
		<script src="js/skel.min.js" defer></script>
		<script src="js/skel-panels.min.js" defer></script>
		<script src="js/init.js" defer></script>
		<noscript>
			<link rel="stylesheet" href="css/skel-noscript.css" />
			<link rel="stylesheet" href="css/style.css" />
			<link rel="stylesheet" href="css/style-desktop.css" />
		</noscript>
		<!--[if lte IE 8]><link rel="stylesheet" href="css/ie/v8.css" /><![endif]-->
		<!--[if lte IE 9]><link rel="stylesheet" href="css/ie/v9.css" /><![endif]-->
	</head>
	<body class="homepage">

		<!-- Header -->
		<div id="header">
			<div class="container"> 
				
				<!-- Logo -->
				<div id="logo">
					<h1><font size="6"><b>Yao Yao</b></font></h1>
					<span class="byline">Associate Professor</span>
					<span class="byline">Nanjing University, Suzhou Campus</span>
				</div>

				<!-- Nav -->
				<nav id="nav">
					<ul>
						<li class="active"><a href="index.html">About</a></li>
						<li><a href="group.html">Group</a></li>
						<li><a href="publications.html">Publications</a></li>
					</ul>
				</nav>
				
			</div>
		</div>

		<!-- Main -->
		<div id="main">
			<div class="container">
				<div class="row"> 
					
					<!-- Sidebar -->
					<div id="sidebar" class="3u">
						<section>
							<img class="img-circle" src="images/face.png" alt="" width="180" loading="lazy">
							<p align="center"><font size="3">Yao Yao (姚遥)</font></p>
							<p align="center"><font size="3">
								<a href="mailto:yaoynju@gmail.com", style="color: rgb(0, 128, 255); text-decoration: none">Email</a> | 
								<a href="https://scholar.google.com/citations?user=MGxaDVEAAAAJ&hl=en", style="color: rgb(0, 128, 255); text-decoration: none">Google Scholar</a> | 
								<a href="https://github.com/YoYo000/", style="color: rgb(0, 128, 255); text-decoration: none">Github</a>
							</font></p>
						</section>
					</div>

					<!-- Content -->
					<div id="content" class="7u skel-cell-important">
						<section>
							<p><font size="5"><b>About</b></font></p>
							<p align='justify'><font size="3">
							I am a Tenure-Track Associate Professor at School of Intelligence Science and Technology, Nanjing University, 
							where I am a member of the 3D Vision Lab (NJU-3DV).
							Previously, I was a senior researcher at Apple, and a founding member of the startup company Altizure (acquired by Apple in 2020). 
							I received my PhD degree from CSE, HKUST in 2019, 
							supervised by Prof. <a href="https://www.cse.ust.hk/~quan/">Long Quan</a>, 
							and my bachelor degree from ECE, NJU in 2015 
							advised by Prof. <a href="https://cite.nju.edu.cn/People/Faculty/20190621/i5054.html">Xun Cao</a>.
							</font></p>
							<br>

							<p><font size="5"><b>Research</b></font></p>
							<p align='justify'><font size="3">
							My research interests lie in intersections of computer vision, computer graphics, and generative models, 
							with a focus on 3D reconstruction and generation. 
							My representative works include the 
							<a href="https://github.com/YoYo000/MVSNet", style="color:rgb(0, 128, 255); text-decoration: none">MVSNet</a> 
							series of works for learning-based multi-view stereo, the  
							<a href="https://yoyo000.github.io/NeILF_pp/", style="color:rgb(0, 128, 255); text-decoration: none">NeILF</a>
							series of works for physically-based differentiable rendering, and the 
							<a href="https://nju-3dv.github.io/projects/Direct3D/", style="color:rgb(0, 128, 255); text-decoration: none">Direct3D</a> 
							series of works for 3D content creation.
							I have won the ICPR 2020 Best Student Paper Award, and is a recipient of 
							the Excellent Young Scholars Fund (Overseas) from NSFC. 
							</font></p>
							<br>


							<p><font size="5"><b>Openings</b></font></p>
							<p align='justify'><font size="3">
							<!-- <span style="color: red; text-decoration: line-through;"> I still have one opening for prospective PhD students (Fall 2025)</span>.  -->
							<!-- <span style="color: red;"> I am actively looking for prospective PostDocs, RAs <span style="color: red; text-decoration: line-through;">, and PhD/master students (Fall 2026)</span> to join my group</span>. Please drop me an email with your research interests and CV if you are interested in our group.</span></p> -->
							I am actively looking for prospective PostDocs and RAs to join my group. Please drop me an email with your research interests and CV if you are interested.</span></p>
							<p style="margin-bottom: 0.5em;">Note: due to a high volume of emails, I may not reply to all. My apologies. </span></p>
							<br>
							
							<p><font size="5"><b>Products</b></font></p>
							<p align='justify'><font size="3">
							I have contributed to the building and shipping of several industrial products:
							<ul style="list-style-type: disc;padding-left: 1em;">
								<li><a style="color:rgb(0, 128, 255); text-decoration: none">Altizure</a></li>
								<li><a href="https://developer.apple.com/videos/play/wwdc2021/10076/", style="color:rgb(0, 128, 255); text-decoration: none">Apple Object Capture API</a></li>
								<li><a href="https://www.neural4d.com/", style="color:rgb(0, 128, 255); text-decoration: none">Neural4D</a></li>
							</ul>
							<br>

							<p><font size="5"><b>News</b></font></p>
							<p class="text" align="Left"><font size="3"></font>	
								<p style="margin-bottom: 0.5em;">2025-12: <a href="https://nju-3dv.github.io/projects/SpatialVID/">TEXTRIX</a> for native texture generation, is now released. </p>
								<p style="margin-bottom: 0.5em;">2025-12: <a href="https://nju-3dv.github.io/projects/SpatialVID/">SlingBAG</a> is accepted by NC </p>
								<p style="margin-bottom: 0.5em;">2025-09: <a href="https://nju-3dv.github.io/projects/SpatialVID/">ComGS</a> for 3DGS composition, is now released. </p>
								<p style="margin-bottom: 0.5em;">2025-09: <a href="https://nju-3dv.github.io/projects/SpatialVID/">SpatialVID</a> dataset for WM training, is now released. </p>
								<p style="margin-bottom: 0.5em;">2025-05: <a href="https://www.neural4d.com/research/direct3d-s2/">Direct3D-S2</a> for 1024^3 3D generation using 8 GPUS, is now released. </p>
								<p style="margin-bottom: 0.5em;">2025-03: <a href="https://nju-3dv.github.io/projects/matrix3d/">Matrix3D</a> for large photogrammetry model, is now released. </p>
								<!-- <p style="margin-bottom: 0.5em;">2025-05: <a href="https://nju-3dv.github.io/projects/fds/">FDS</a> for 3DGS reconstruction with prior optical flow model, is now released. </p> -->
								<!-- <p style="margin-bottom: 0.5em;">2024-08: <a href="https://arxiv.org/pdf/2407.11781">SLINGBAG</a> and <a href="https://arxiv.org/pdf/2408.12419">4DProtein</a> on 3D for Science, is now released.  </p> -->
								<!-- <p style="margin-bottom: 0.5em;">2024-05: <a href="https://nju-3dv.github.io/projects/Direct3D">Direct3D</a> for scalable 3D generation with 3D latent DiT, is now released. </p> -->
								<!-- <p style="margin-bottom: 0.5em;">2024-05: <a href="https://gaoxiangjun.github.io/mani_gs/">Mani-GS</a> for high-quality 3DGS editing, is now released. </p> -->
								<!-- <p style="margin-bottom: 0.5em;">2024-03: <a href="https://nju-3dv.github.io/projects/STAG4D">STAG4D</a> for high-quality 4D generation, is now released. </p> -->
								<!-- <p style="margin-bottom: 0.5em;">2024-03: <a href="https://fudan-generative-vision.github.io/champ/#/">Ghamp</a> for 2D human animation, is now released. </p> -->
								<!-- <p style="margin-bottom: 0.5em;">2023-12: <a href="https://nju-3dv.github.io/projects/Gaussian-Flow">Gaussian-Flow</a> for ultra fast 4D reconstruction/rendering, is now released. </p> -->
								<!-- <p style="margin-bottom: 0.5em;">2023-11: <a href="https://nju-3dv.github.io/projects/Relightable3DGaussian/">Relightable 3DGS</a> for point-based graphics pipeline, is now released. </p> -->
								<!-- <p style="margin-bottom: 0.5em;">2023-11: <a href="https://nju-3dv.github.io/projects/direct25/">Direct2.5</a> for ultra fast and diverse text-to-3D generation, is now released. </p> -->
								<!-- <p style="margin-bottom: 0.5em;">2023-11: <a href="https://consistent4d.github.io/">Consistent4D</a> for video-to-4D generation, is now released. </p> -->
								<!-- <p style="margin-bottom: 0.5em;">2023-10: <a href="https://jzhangbs.github.io/jointnet_proj_page/">JointNet</a> for dense distribution modeling, is now released. </p> -->
								<!-- <p style="margin-bottom: 0.5em;">2023-05: After three wonderful years at Apple, I have resigned and will start a new journey at Nanjing University as a faculty member. </p> -->
								<!-- <p style="margin-bottom: 0.5em;">2023-03-30: <a href="https://yoyo000.github.io/NeILF_pp/">NeILF++</a> on joint geometry, material and lighting optimization, is now released. </p> -->
								<!-- <p style="margin-bottom: 0.5em;">2022-09-26: <a href="https://link.springer.com/article/10.1007/s11263-022-01697-3">Vis-MVSNet</a> (an extended version) is accepted to IJCV as an invited paper. </p> -->
								<!-- <p style="margin-bottom: 0.5em;">2022-03-14: <a href="https://arxiv.org/pdf/2203.07182.pdf">NeILF</a> on material and lighting estimation, is now available at arxiv. </p> -->
								<!-- <p style="margin-bottom: 0.5em;">2022-03-03: <a href="https://arxiv.org/abs/2206.03087">RegSDF</a> on neural surface reconstruction, is accepted to CVPR2022. </p> -->
								<!-- <p style="margin-bottom: 0.5em;">2021-07-23: <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_Learning_Signed_Distance_Field_for_Multi-View_Surface_Reconstruction_ICCV_2021_paper.pdf">MVSDF</a> is accepted to ICCV2021 as an oral presentation. </p> -->
							</font></p>
							<br>


							<p class="text" align="center"> Last updated: 2025.09.08</p>
							<br>
						
						</section>
					</div>
				</div>
			</div>
		</div>

	</body>
</html>
