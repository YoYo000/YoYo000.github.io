<!DOCTYPE HTML>
<!--
	Iridium by TEMPLATED
    templated.co @templatedco
    Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>
		<title>Yao Yao</title>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="description" content="" />
		<meta name="keywords" content="" />
		<!-- <link href='http://fonts.googleapis.com/css?family=Arimo:400,700' rel='stylesheet' type='text/css'> -->
		<!--[if lte IE 8]><script src="js/html5shiv.js"></script><![endif]-->
		<!-- <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script> -->
		<script src="js/skel.min.js"></script>
		<script src="js/skel-panels.min.js"></script>
		<script src="js/init.js"></script>
		<noscript>
			<link rel="stylesheet" href="css/skel-noscript.css" />
			<link rel="stylesheet" href="css/style.css" />
			<link rel="stylesheet" href="css/style-desktop.css" />
		</noscript>
		<!--[if lte IE 8]><link rel="stylesheet" href="css/ie/v8.css" /><![endif]-->
		<!--[if lte IE 9]><link rel="stylesheet" href="css/ie/v9.css" /><![endif]-->
	</head>
	<body class="homepage">

		<!-- Header -->
		<div id="header">
			<div class="container"> 
				
				<!-- Logo -->
				<div id="logo">
					<h1><font size="6"><b>Yao Yao</b></font></h1>
					<span class="byline">Associate Professor</span>
					<span class="byline">Nanjing University, Suzhou Campus</span>
				</div>

				<!-- Nav -->
				<nav id="nav">
					<ul>
						<li><a href="index.html">About</a></li>
						<li><a href="group.html">Group</a></li>
						<li  class="active"><a href="publications.html">Publications</a></li>
					</ul>
				</nav>
			</div>
		</div>

		<!-- Main -->
		<div id="main">
			<div class="container">
				<div class="row"> 
					
					<!-- Content -->
					<div id="content" class="12u skel-cell-important">
						<section>

							<p><font size="5"><b>Publications</b></font> </p>
							
							<p><font size="3">Also find my full publication list at <a href="https://scholar.google.com/citations?user=MGxaDVEAAAAJ&hl=en", style="color: rgb(0, 128, 255); text-decoration: none">Google Scholar</a>.</font></p>
							<br/>

							
							<font size="4">2024</font><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/stag4d.png" height="70" width="180" loading="lazy"></div>
								<div><font size="3"><b>STAG4D: Spatial-Temporal Anchored Generative 4D Gaussians</b> 
									[<a href="https://arxiv.org/abs/2403.14939", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="https://nju-3dv.github.io/projects/STAG4D/", style="color: rgb(0, 128, 255); text-decoration: none">project</a>] </font></div>
								<span><font size="3"> Yifei Zeng*, Yanqin Jiang*, Siyu Zhu, Yuanxun Lu, Youtian Lin, Hao Zhu, Weiming Hu, Xun Cao, <b>Yao Yao</b><sup><span style="font-family:Wingdings">*</span></sup>
								</font></span>
								<div><span><font size="3">arXiv preprint 2403.14939</font></span> <span></span></div>
							</div><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/champ.png" height="80" width="180" loading="lazy"></div>
								<div><font size="3"><b>Champ: Controllable and Consistent Human Image Animation with 3D Parametric Guidance</b> 
									[<a href="https://arxiv.org/abs/2403.14781", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="https://fudan-generative-vision.github.io/champ/#/", style="color: rgb(0, 128, 255); text-decoration: none">project</a>] </font></div>
								<span><font size="3"> Shenhao Zhu*, Junming Leo Chen*, Zuozhuo Dai, Yinghui Xu, Xun Cao, <b>Yao Yao</b>, Hao Zhu, Siyu Zhu
								</font></span>
								<div><span><font size="3">arXiv preprint 2403.14781</font></span> <span></span></div>
							</div><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/gaussianpro.png" height="90" width="180" loading="lazy"></div>
								<div><font size="3"><b>GaussianPro: 3D Gaussian Splatting with Progressive Propagation</b> 
									[<a href="https://arxiv.org/abs/2402.14650", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="https://kcheng1021.github.io/gaussianpro.github.io/", style="color: rgb(0, 128, 255); text-decoration: none">project</a>] </font></div>
								<span><font size="3"> Kai Cheng*, Xiaoxiao Long*, Kaizhi Yang, <b>Yao Yao</b>, Wei Yin, Yuexin Ma, Wenping Wang, Xuejin Chen
								</font></span>
								<div><span><font size="3">arXiv preprint 2402.14650</font></span> <span></span></div>
							</div><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/direct2.5.png" height="90" width="180" loading="lazy"></div>
								<div><font size="3"><b>Direct2.5: Diverse Text-to-3D Generation via Multi-view 2.5D Diffusion</b> 
									[<a href="https://arxiv.org/abs/2311.15980", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="https://nju-3dv.github.io/projects/direct25/", style="color: rgb(0, 128, 255); text-decoration: none">project</a>] </font></div>
								<span><font size="3"> Yuanxun Lu, Jingyang Zhang, Shiwei Li, Tian Fang, David McKinnon, Yanghai Tsin, Long Quan, Xun Cao, <b>Yao Yao</b><sup><span style="font-family:Wingdings">*</span></sup>
								</font></span>
								<div><span><font size="3">Computer Vision and Pattern Recognition (CVPR) 2024</font></span> <span></span></div>
							</div><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/gaussian-flow.png" height="70" width="180" loading="lazy"></div>
								<div><font size="3"><b>Gaussian-Flow: 4D Reconstruction with Dynamic 3D Gaussian Particle</b> 
									[<a href="https://arxiv.org/abs/2312.03431", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="https://nju-3dv.github.io/projects/Gaussian-Flow/", style="color: rgb(0, 128, 255); text-decoration: none">project</a>] </font></div>
								<span><font size="3"> Youtian Lin, Zuozhuo Dai, Siyu Zhu, <b>Yao Yao</b><sup><span style="font-family:Wingdings">*</span></sup>
								<div><span><font size="3">Computer Vision and Pattern Recognition (CVPR) 2024</font></span> <span></span></div>
							</div><br/><br/>
							
							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/consistent4d.png" height="90" width="180" loading="lazy"></div>
								<div><font size="3"><b>Consistent4D: Consistent 360 Dynamic Object Generation from Monocular Video</b> 
									[<a href="https://arxiv.org/abs/2311.02848", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="https://consistent4d.github.io/", style="color: rgb(0, 128, 255); text-decoration: none">project</a>] </font></div>
								<span><font size="3"> Yanqin Jiang, Li Zhang, Jin Gao, Weiming Hu, <b>Yao Yao</b><sup><span style="font-family:Wingdings">*</span></sup>
								</font></span>
								<div><span><font size="3">International Conference on Learning Representations (ICLR) 2024</font></span> <span></span></div>
							</div><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/jointnet.png" height="90" width="180" loading="lazy"></div>
								<div><font size="3"><b>JointNet: Extending Text-to-Image Diffusion for Dense Distribution Modeling</b> 
									[<a href="https://arxiv.org/abs/2310.06347", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="https://jzhangbs.github.io/jointnet_proj_page/", style="color: rgb(0, 128, 255); text-decoration: none">project</a>] </font></div>
								<span><font size="3"> Jingyang Zhang, Shiwei Li, Yuanxun Lu, Tian Fang, David McKinnon, Yanghai Tsin, Long Quan, <b>Yao Yao</b><sup><span style="font-family:Wingdings">*</span></sup>
								</font></span>
								<div><span><font size="3">International Conference on Learning Representations (ICLR) 2024</font></span> <span></span></div>
							</div><br/><br/>


							<font size="4">2023</font><br/><br/>
							
							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/animateanything.png" height="100" width="180" loading="lazy"></div>
								<div><font size="3"><b>AnimateAnything: Fine-Grained Open Domain Image Animation with Motion Guidance</b> 
									[<a href="https://arxiv.org/abs/2311.12886", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="https://animationai.github.io/AnimateAnything/", style="color: rgb(0, 128, 255); text-decoration: none">project</a>] </font></div>
								<span><font size="3"> Zuozhuo Dai, Zhenghao Zhang, <b>Yao Yao</b>, Bingxue Qiu, Siyu Zhu, Long Qin, Weizhi Wang
								</font></span>
								<div><span><font size="3">arXiv preprint 2311.12886</font></span> <span></span></div>
							</div><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/brdf-3dgs.png" height="80" width="180" loading="lazy"></div>
								<div><font size="3"><b>Relightable 3D Gaussian: Real-time Point Cloud Relighting with BRDF Decomposition and Ray Tracing</b> 
									[<a href="https://arxiv.org/abs/2311.16043", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="https://nju-3dv.github.io/projects/Relightable3DGaussian/", style="color: rgb(0, 128, 255); text-decoration: none">project</a>] </font></div>
								<span><font size="3"> Jian Gao, Chun Gu, Youtian Lin, Hao Zhu, Xun Cao, Li Zhang<sup><span style="font-family:Wingdings">*</span></sup>, <b>Yao Yao</b><sup><span style="font-family:Wingdings">*</span></sup>
								</font></span>
								<div><span><font size="3">arXiv preprint 2311.16043</font></span> <span></span></div>
							</div><br/><br/>


							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/avatarbooth.png" height="85" width="180" loading="lazy"></div>
								<div><font size="3"><b>AvatarBooth: High-Quality and Customizable 3D Human Avatar Generation</b> 
									[<a href="https://arxiv.org/abs/2306.09864", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="https://zeng-yifei.github.io/avatarbooth_page/", style="color: rgb(0, 128, 255); text-decoration: none">project</a>] </font></div>
								<span><font size="3">Yifei Zeng, Yuanxun Lu, Xinya Ji, <b>Yao Yao</b>, Hao Zhu<sup><span style="font-family:Wingdings">*</span></sup>, Xun Cao
								</font></span>
								<div><span><font size="3">arXiv preprint 2306.09864</font></span> <span></span></div>
							</div><br/><br/>
							
							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/aa-nerf.png" height="80" width="180" loading="lazy"></div>
								<div><font size="3"><b>Anti-Aliased Neural Implicit Surfaces with Encoding Level of Detail</b> 
									[<a href="https://arxiv.org/abs/2309.10336", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="https://arxiv.org/abs/2309.10336", style="color: rgb(0, 128, 255); text-decoration: none">project</a>] </font></div>
								<span><font size="3"> Yiyu Zhuang, Qi Zhang, Ying Feng, Hao Zhu, <b>Yao Yao</b>, Xiaoyu Li, Yan-Pei Cao, Ying Shan, Xun Cao
								</font></span>
								<div><span><font size="3">Siggraph Asia 2023</font></span> <span></span></div>
							</div><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/neilf_pp.png" height="90" width="180" loading="lazy"></div>
								<div><font size="3"><b>NeILF++: Inter-Reflectable Light Fields for Geometry and Material Estimation</b> 
									[<a href="https://arxiv.org/abs/2303.17147", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="https://yoyo000.github.io/NeILF_pp/", style="color: rgb(0, 128, 255); text-decoration: none">project</a>] </font></div>
								<span><font size="3">Jingyang Zhang, <b>Yao Yao</b><sup><span style="font-family:Wingdings">*</span></sup>, Shiwei Li, Jingbo Liu, Tian Fang, David McKinnon, Yanghai Tsin, Long Quan
								</font></span>
								<div><span><font size="3">International Conference on Computer Vision (ICCV) 2023</font></span> <span></span></div>
							</div><br/><br/>

							
							<font size="4">2022</font><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/vis-mvsnet-ijcv.png" height="90" width="180" loading="lazy"></div>
								<div><font size="3"><b>Vis-MVSNet: Visibility-Aware Multi-view Stereo Network</b> 
									[<a href="https://link.springer.com/article/10.1007/s11263-022-01697-3", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="https://github.com/jzhangbs/Vis-MVSNet", style="color: rgb(0, 128, 255); text-decoration: none">code</a>] </font></div>
								<span><font size="3">Jingyang Zhang, Shiwei Li, Zixin Luo, Tian Fang, <b>Yao Yao</b><sup><span style="font-family:Wingdings">*</span></sup> </font></span>
								<div><span><font size="3">International Journal of Computer Vision (IJCV) 2022</font></span>  <span>(<font size="4", color="#FF0000">invited paper</font>)</span></div>
							</div><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/neilf.png" height="90" width="180" loading="lazy"></div>
								<div><font size="3"><b>NeILF: Neural Incident Light Field for Physically-based Material Estimation</b> 
									[<a href="https://arxiv.org/pdf/2203.07182.pdf", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="https://github.com/apple/ml-neilf", style="color: rgb(0, 128, 255); text-decoration: none">code</a>]
									[<a href="https://apple.ent.box.com/s/epkd7hamlpd7ltrsy4fyilzci19rz84r", style="color: rgb(0, 128, 255); text-decoration: none">data</a>] </font></div>
								<span><font size="3"><b>Yao Yao</b>, Jingyang Zhang, Jingbo Liu, Yihang Qu, Tian Fang, David McKinnon, Yanghai Tsin, Long Quan</font></span>
								<div><span><font size="3">European Conference on Computer Vision (ECCV) 2022</font></span> <span></span></div>
							</div><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/regsdf.png" height="80" width="180" loading="lazy"></div>
								<div><font size="3"><b>Critical Regularizations for Neural Surface Reconstruction in the Wild</b> 
									[<a href="papers/zhang2021regsdf.pdf", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>] </font></div>
								<span><font size="3">Jingyang Zhang, <b>Yao Yao</b><sup><span style="font-family:Wingdings">*</span></sup>, Shiwei Li, Tian Fang, David McKinnon, Yanghai Tsin, Long Quan</font></span>
								<div><span><font size="3">Computer Vision and Pattern Recognition (CVPR) 2022</font></span> <span></span></div>
							</div><br/><br/>

							
							<font size="4">2021</font><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/mvsdf.png" height="80" width="180" loading="lazy"></div>
								<div><font size="3"><b>Learning Signed Distance Field for Multi-view Surface Reconstruction</b> 
									[<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_Learning_Signed_Distance_Field_for_Multi-View_Surface_Reconstruction_ICCV_2021_paper.pdf", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="https://github.com/jzhangbs/MVSDF", style="color: rgb(0, 128, 255); text-decoration: none">code</a>] </font></div>
								<span><font size="3">Jingyang Zhang, <b>Yao Yao</b><sup><span style="font-family:Wingdings">*</span></sup>, Long Quan</font></span>
								<div><span><font size="3">International Conference on Computer Vision (ICCV) 2021</font></span> <span>(<font size="4", color="#FF0000">oral</font>)</span></div>
							</div><br/><br/>
							

							<font size="4">2020</font><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/vis-mvsnet.png" height="80" width="180" loading="lazy"></div>
								<div><font size="3"><b>Visibility-aware Multi-view Stereo Network</b> 
									[<a href="https://arxiv.org/pdf/2008.07928.pdf", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="https://github.com/jzhangbs/Vis-MVSNet", style="color: rgb(0, 128, 255); text-decoration: none">code</a>] </font></div>
								<span><font size="3">Jingyang Zhang, <b>Yao Yao</b><sup><span style="font-family:Wingdings">*</span></sup>, Shiwei Li, Zixin Luo, Tian Fang</font></span>
								<div><span><font size="3">British Machine Vision Conference (BMVC) 2020 </font></span> <span>(<font size="4", color="#FF0000">oral</font>)</span></div>
							</div><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/dsm.png" height="80" width="180" loading="lazy"></div>
								<div><font size="3"><b>Learning Stereo Matchability in Disparity Regression Networks</b> 
									[<a href="https://arxiv.org/pdf/2008.04800.pdf", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="https://github.com/jzhangbs/DSM", style="color: rgb(0, 128, 255); text-decoration: none">code</a>] </font></div>
								<span><font size="3">Jingyang Zhang, <b>Yao Yao</b><sup><span style="font-family:Wingdings">*</span></sup>, Zixin Luo, Shiwei Li, Tianwei Shen, Tian Fang, Long Quan</font></span>
								<div><span><font size="3">International Conference on Pattern Recognition (ICPR) 2020</font></span> <span>(<font size="4", color="#FF0000">best student paper award</font>)</span></div>
							</div><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/blendedmvs.png" height="90" width="180" loading="lazy"></div>
								<div><font size="3"><b>BlendedMVS: A Large-scale Dataset for Generalized Multi-view Stereo Networks</b> 
									[<a href="https://arxiv.org/pdf/1911.10127.pdf", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="https://github.com/YoYo000/BlendedMVS", style="color: rgb(0, 128, 255); text-decoration: none">dataset</a>] </font></div>
								<span><font size="3"><b>Yao Yao</b>, Zixin Luo, Shiwei Li, Jingyang Zhang, Yufan Ren, Lei Zhou, Tian Fang, Long Quan</font></span>
								<div><span><font size="3">Computer Vision and Pattern Recognition (CVPR) 2020 </font></span></div>
							</div><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/aslfeat.png" height="90" width="180" loading="lazy"></div>
								<div><font size="3"><b>ASLFeat: Learning Local Features of Accurate Shape and Localization</b> 
									[<a href="https://arxiv.org/pdf/2003.10071.pdf", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="https://github.com/lzx551402/ASLFeat", style="color: rgb(0, 128, 255); text-decoration: none">code</a>] </font></div>
								<span><font size="3">Zixin Luo, Lei Zhou, Xuyang Bai, Hongkai Chen, Jiahui Zhang, <b>Yao Yao</b>, Shiwei Li, Tian Fang, Long Quan</font></span>
								<div><span><font size="3">Computer Vision and Pattern Recognition (CVPR) 2020</font></span></div>
							</div><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/kfnet.png" height="90" width="180" loading="lazy"></div>
								<div><font size="3"><b>Learning Temporal Camera Relocalization using Kalman Filtering</b> 
									[<a href="https://arxiv.org/pdf/2003.10629.pdf", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="https://github.com/zlthinker/KFNet", style="color: rgb(0, 128, 255); text-decoration: none">code</a>] </font></div>
								<span><font size="3">Lei Zhou, Zixin Luo, Tianwei Shen, Jiahui Zhang, Mingmin Zhen, <b>Yao Yao</b>, Tian Fang, Long Quan</font></span>
								<div><span><font size="3">Computer Vision and Pattern Recognition (CVPR) 2020</font></span> <span>(<font size="4", color="#FF0000">oral</font>)</span></div>
							</div><br/><br/>


							<font size="4">2019</font><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/jointposedepth.png" height="90" width="180" loading="lazy"></div>
								<div><font size="3"><b>Self-Supervised Learning of Depth and Motion Under Photometric Inconsistency</b> 
									[<a href="https://arxiv.org/pdf/1909.09115.pdf", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="https://github.com/hlzz/DeepMatchVO", style="color: rgb(0, 128, 255); text-decoration: none">code</a>] </font></div>
								<span><font size="3">Tianwei Shen, Lei Zhou, Zixin Luo, <b>Yao Yao</b>, Shiwei Li, Jiahui Zhang, Tian Fang, Long Quan</font></span>
								<div><span><font size="3"> International Conference on Computer Vision Workshops (ICCVW) 2019</font></span></div>
							</div><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/R-MVSNet.png" height="90" width="180" loading="lazy"></div>
								<div><font size="3"><b>Recurrent MVSNet for High-resolution Multi-view Stereo Depth Inference</b> 
									[<a href="https://arxiv.org/pdf/1902.10556.pdf", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="https://github.com/YoYo000/MVSNet", style="color: rgb(0, 128, 255); text-decoration: none">code</a>] </font></div>
								<span><font size="3"><b>Yao Yao</b>, Zixin Luo, Shiwei Li, Tianwei Shen, Tian Fang, Long Quan</font></span>
								<div><span><font size="3">Computer Vision and Pattern Recognition (CVPR) 2019 </font></span></div>
							</div><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/texconv.png" height="90" width="180" loading="lazy"></div>
								<div><font size="3"><b>Cross-atlas Convolution for Parameterization Invariant Learning on Textured Mesh Surface</b> 
									[<a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Cross-Atlas_Convolution_for_Parameterization_Invariant_Learning_on_Textured_Mesh_Surface_CVPR_2019_paper.pdf", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]</font></div>
								<span><font size="3">Shiwei Li, Zixin Luo, Mingmin Zhen, <b>Yao Yao</b>, Tianwei Shen, Tian Fang, Long Quan</font></span>
								<div><span><font size="3">Computer Vision and Pattern Recognition (CVPR) 2019 </font></span></div>
							</div><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/crossmodality.png" height="90" width="180" loading="lazy"></div>
								<div><font size="3"><b>ContextDesc: Local Descriptor Augmentation with Cross-Modality Context</b> 
									[<a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Luo_ContextDesc_Local_Descriptor_Augmentation_With_Cross-Modality_Context_CVPR_2019_paper.pdf", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="https://github.com/lzx551402/contextdesc", style="color: rgb(0, 128, 255); text-decoration: none">code</a>]</font></div>
								<span><font size="3">Zixin Luo, Tianwei Shen, Lei Zhou, Jiahui Zhang, <b>Yao Yao</b>, Shiwei Li, Tian Fang, Long Quan</font></span>
								<div><span><font size="3">Computer Vision and Pattern Recognition (CVPR) 2019</font></span> <span>(<font size="4", color="#FF0000">oral</font>)</span></div>
							</div><br/><br/>

							
							<font size="4">2018</font><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/mvsnet.jpg" height="80" width="180" loading="lazy"></div>
								<div><font size="3"><b>MVSNet: Depth Inference for Unstructured Multi-view Stereo</b> 
									[<a href="papers/yao2018mvsnet.pdf", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="papers/yao2018mvsnet_supp.pdf", style="color: rgb(0, 128, 255); text-decoration: none">supp</a>]
									[<a href="https://github.com/YoYo000/MVSNet", style="color: rgb(0, 128, 255); text-decoration: none">code</a>]</font></div>
								<span><font size="3"><b>Yao Yao</b>, Zixin Luo, Shiwei Li, Tian Fang, Long Quan</font></span>
								<div><span><font size="3">European Conference on Computer Vision (ECCV) 2018</font></span> <span>(<font size="4", color="#FF0000">oral</font>)</span></div>
							</div><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/geodesc.png" height="80" width="180" loading="lazy"></div>
								<div><font size="3"><b>GeoDesc: Learning Local Descriptors by Integrating Geometry Constraints</b> 
									[<a href="https://arxiv.org/abs/1807.06294", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="https://github.com/lzx551402/geodesc", style="color: rgb(0, 128, 255); text-decoration: none">code</a>]</font></div>
								<span><font size="3">Zixin Luo, Tianwei Shen, Lei Zhou, Siyu Zhu, Runze Zhang, <b>Yao Yao</b>, Tian Fang, Long Quan</font></span>
								<div><span><font size="3">European Conference on Computer Vision (ECCV) 2018</font></span></div>
							</div><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/thin.png" height="80" width="180" loading="lazy"></div>
								<div><font size="3"><b>Reconstructing Thin Structures of Manifold Surfaces by Integrating Spatial Curves</b> 
									[<a href="papers/shiwei2018reconstructing.pdf", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]
									[<a href="papers/shiwei2018reconstructing_supp.pdf", style="color: rgb(0, 128, 255); text-decoration: none">supp</a>]</b><font></div>
								<span><font size="3">Shiwei Li, <b>Yao Yao</b>, Tian Fang, Long Quan</font></span>
								<div><span><font size="3">Computer Vision and Pattern Recognition (CVPR) 2018</font></span></div>
							</div><br/><br/>

							
							<font size="4">2017</font><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/rcr.jpg" height="85" width="180" loading="lazy"></div>
								<div><font size="3"><b>Reletive Camera Refinement for Accurate Dense Reconstruction</b> 
									[<a href="papers/yao2017relative.pdf", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]</b><font></div>
								<span><font size="3"><b>Yao Yao</b>, Shiwei Li, Siyu Zhu, Hanyu Deng, Tian Fang, Long Quan</font></span>
								<div><span><font size="3">International Conference on 3D Vision (3DV) 2017</font></span> <span>(<font size="4", color="#FF0000">spotlight oral</font>)</span></div>
							</div><br/><br/>

							
							<font size="4">2014</font><br/><br/>

							<div>
								<div style="display:inline;float:left;margin:5px 10px 0px 0px"><img src="images/teasers/revised.jpg" height="85" width="180" loading="lazy"></div>
								<div><font size="3"><b>Revised depth map estimation for multi-view stereo</b> 
									[<a href="papers/yao2014revised.pdf", style="color: rgb(0, 128, 255); text-decoration: none">paper</a>]</b><font></div>
								<span><font size="3"><b>Yao Yao</b>, Hao Zhu, Yongming Nie, Xiaoli Ji, Xun Cao</font></span>
								<div><span><font size="3">International Conference on 3D Imaging (IC3D) 2014</font></span> <span>(<font size="4", color="#FF0000">oral</font>)</span></div>
							</div><br/><br/>

						</section>
					</div>
					
				</div>
			</div>
		</div>
		
	</body>
</html>
